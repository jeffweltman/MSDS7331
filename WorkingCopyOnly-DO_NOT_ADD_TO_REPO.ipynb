{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2 - Classification and Regression\n",
    "\n",
    "Team Members:\n",
    "* Jeff Weltman\n",
    "* Jordan Kassof\n",
    "* Kevin Dickens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparation 1 \n",
    "## Preparing Target Variables\n",
    "\n",
    "In our classification task, we will be predicting a binary variable that indicates whether or not a highschool's average SAT score is considered \"outperforming.\" This indicator variable is derived based on a threshold applied to the numeric average score. If a school's average SAT score is above 1080, for the purposes of this analysis, it is considered outperforming. While these classes aren't perfectly even, that is expected. It would be surprising to see an equal amount of outperforming and non-outperforming schools. The 262-159 class split isn't large enough for us to worry too much about class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Initial dataset\n",
    "hs_2017 = pd.read_csv(\"hs_2017.csv\")\n",
    "\n",
    "# Preparing the Classification variables\n",
    "Y_class = hs_2017['sat_high_level']\n",
    "X_class = hs_2017.drop(columns=['nc_district', 'sat_high_level', 'sat_avg_score_num'])\n",
    "\n",
    "# Preparing the Regression variables\n",
    "Y_reg = hs_2017['GraduationRate_5yr_All']\n",
    "X_reg = hs_2017.drop(columns=['sat_high_level','sat_avg_score_num','lea_sat_avg_score_num'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Variable\n",
    "\n",
    "In our classification task, we will be predicting a binary integer variable that represents a one-hot encoding of whether or not a highschool's average SAT score \"outperforms\" expectations.  This indicator variable is derived based on a threshold applied to the numeric average score. If a school's average SAT score is above 1080, for the purposes of this analysis, it is considered outperforming. While these classes aren't perfectly even, that is expected. It would be surprising to see an equal amount of outperforming and non-outperforming schools. The 262-159 class split isn't large enough for us to worry too much about class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    262\n",
       "1.0    159\n",
       "Name: sat_high_level, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Checking Classification Variable Balance\n",
    "hs_2017.sat_high_level.value_counts().plot(kind='bar')\n",
    "plt.title(\"Non-Outperform and Outperform Counts\")\n",
    "plt.ylabel(\"Number of Schools\")\n",
    "plt.show()\n",
    "hs_2017.sat_high_level.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Variable\n",
    "\n",
    "In our regression task, we will be predicting the 5-year graduation rate for high schools in the public school system of North Carolina.  This variable represents the percentage of students graduating after five years and is stored as a floating point value.  This data was collected by the north carolina education department for the purpose of tracking school performance.  The distribution of the data follows a normal gaussian distribution although some 0 values are present which create a long tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    100.0\n",
       "1     86.9\n",
       "2     85.7\n",
       "3     74.8\n",
       "4     83.6\n",
       "Name: GraduationRate_5yr_All, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking  Regression Variable Distribution\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Cut the window in 2 parts\n",
    "f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\": (.15, .85)})\n",
    " \n",
    "# Add a graph in each part\n",
    "\n",
    "box = sns.boxplot(hs_2017[\"GraduationRate_5yr_All\"], ax=ax_box)\n",
    "dist = sns.distplot(hs_2017[\"GraduationRate_5yr_All\"], ax=ax_hist)\n",
    "\n",
    "box.set_title(\"Distribution of 5 Year Graduation Rates\\n\")\n",
    "\n",
    "# Remove x axis name for the boxplot\n",
    "ax_box.set(xlabel='')\n",
    "\n",
    "plt.show()\n",
    "hs_2017.GraduationRate_5yr_All.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling\n",
    "\n",
    "In an attempt to correct distibution issues, we've scaled the data for both classification and regression tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the data to a more normally distributed data\n",
    "scaler_class = StandardScaler()\n",
    "scaler_class.fit(X_class)\n",
    "\n",
    "scaler_reg = StandardScaler()\n",
    "scaler_reg.fit(X_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Preparation 2\n",
    "## Final Dataset\n",
    "\n",
    "This dataset underwent preprocessing prior to this project.  As a result the quality and integrity were at suitably high levels for the project needs.  During that preprocessing many columns were removed if they contained more than 60% null values and null values were then imputed with zeros across the rest of the data.  In practice, most columns either held a large amount of NULL values or none at all.\n",
    "\n",
    "For SAT data schools were removed if they did not report values either from masking due to low participation or actual no data available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modeling and Evaluation 1\n",
    "## Evaluation Metrics\n",
    "This section will discuss the measures of evaluation for both classification and regression tasks as well as define functions for use later in the code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "For classification, we opted to use precision as our scoring metric. As we sought to most accurately predict whether a school would overperform on average SAT score, we concluded that minimizing false positives would be of greatest value. The cost of mis-classifying a school as not overperforming when they were, in fact, overperforming was deemed lower than the alternative. \n",
    "\n",
    "Below we define a custom Classification Evaluation function, [created by Dr. Jake Drew](https://github.com/jakemdrew/EducationDataNC/blob/master/2017/Models/2017ComparingSegregatedHighSchoolCampuses.ipynb), to efficiently determine a given model's accuracy, precision, and recall.  \n",
    "We will utilize this function to assess model performance in classifying whether a school is or is not overperforming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def EvaluateClassifierEstimator(classifierEstimator, X, y, cv):\n",
    "   \n",
    "    #Perform cross validation \n",
    "    scores = cross_validate(classifierEstimator, X, y, scoring=['accuracy','precision','recall']\n",
    "                            , cv=cv, return_train_score=True)\n",
    "\n",
    "    Accavg = scores['test_accuracy'].mean()\n",
    "    Preavg = scores['test_precision'].mean()\n",
    "    Recavg = scores['test_recall'].mean()\n",
    "\n",
    "    print_str = \"The average accuracy for all cv folds is: \\t\\t\\t {Accavg:.5}\"\n",
    "    print_str2 = \"The average precision for all cv folds is: \\t\\t\\t {Preavg:.5}\"\n",
    "    print_str3 = \"The average recall for all cv folds is: \\t\\t\\t {Recavg:.5}\"\n",
    "\n",
    "    print(print_str.format(Accavg=Accavg))\n",
    "    print(print_str2.format(Preavg=Preavg))\n",
    "    print(print_str3.format(Recavg=Recavg))\n",
    "    print('*********************************************************')\n",
    "\n",
    "    print('Cross Validation Fold Mean Error Scores')\n",
    "    scoresResults = pd.DataFrame()\n",
    "    scoresResults['Accuracy'] = scores['test_accuracy']\n",
    "    scoresResults['Precision'] = scores['test_precision']\n",
    "    scoresResults['Recall'] = scores['test_recall']\n",
    "\n",
    "    return scoresResults\n",
    "\n",
    "def EvaluateClassifierEstimator2(classifierEstimator, X, y, cv):\n",
    "    \n",
    "    #Perform cross validation \n",
    "    from sklearn.model_selection import cross_val_predict\n",
    "    predictions = cross_val_predict(classifierEstimator, X_Class, Y_Class, cv=cv)\n",
    "    \n",
    "    #model evaluation \n",
    "    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "    \n",
    "    #pass true test set values and predictions to classification_report\n",
    "    classReport = classification_report(Y,predictions)\n",
    "    confMat = confusion_matrix(Y,predictions)\n",
    "    acc = accuracy_score(Y,predictions)\n",
    "    \n",
    "    print(classReport)\n",
    "    print(confMat)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a function to plot out the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression\n",
    "*Root Mean Squared Error* (RMSE) was utilized as our primary regression models' scoring criterion. This represented the degree to which our predicted model deviated from the actual data. It is widely used in regression task as a measurement of variance between the predicted and actual data and was therefore deemed the most appropriate metric for our regression tasks. RMSE is considered appropriate to represent model performance when the error distribution is normally distributed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer, mean_squared_error\n",
    "\n",
    "# Define function for Root mean squared error\n",
    "#https://stackoverflow.com/questions/17197492/root-mean-square-error-in-python\n",
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "#define Function for Mean Absolute Percentage Error (MAPE)\n",
    "#From: https://github.com/jakemdrew/EducationDataNC/blob/master/Other%20Projects/iPython%20Notebooks/Machine%20Learning/Graduation%20Rates%20February%202018%20-%205%20Years%20Expanded.ipynb\n",
    "#Adapted from: https://stackoverflow.com/questions/42250958/how-to-optimize-mape-code-in-python\n",
    "def mape(y, y_pred): \n",
    "    mask = y != 0\n",
    "    return (np.fabs(y - y_pred)/y)[mask].mean() * 100\n",
    "\n",
    "#Scoring functions\n",
    "mae_scorer = make_scorer(score_func=mean_absolute_error, greater_is_better=False)\n",
    "rmse_scorer = make_scorer(score_func=rmse, greater_is_better=False)\n",
    "mape_scorer = make_scorer(score_func=mape, greater_is_better=False)\n",
    "\n",
    "#Array created to score individual folds\n",
    "errorScoring = {'MAE':  mae_scorer, \n",
    "                'RMSE': rmse_scorer,\n",
    "                'MAPE': mape_scorer\n",
    "               }\n",
    "\n",
    "\n",
    "def EvaluateRegressionEstimator(regEstimator, X, y, cv):\n",
    "    \n",
    "    scores = cross_validate(regEstimator, X, y, scoring=errorScoring, cv=cv, return_train_score=True)\n",
    "\n",
    "    #cross val score sign-flips the outputs of MAE\n",
    "    #From: https://github.com/jakemdrew/EducationDataNC/blob/master/Other%20Projects/iPython%20Notebooks/Machine%20Learning/Graduation%20Rates%20February%202018%20-%205%20Years%20Expanded.ipynb\n",
    "    #Adapted from: https://github.com/scikit-learn/scikit-learn/issues/2439\n",
    "    scores['test_MAE'] = scores['test_MAE'] * -1\n",
    "    scores['test_MAPE'] = scores['test_MAPE'] * -1\n",
    "    scores['test_RMSE'] = scores['test_RMSE'] * -1\n",
    "\n",
    "    #print mean MAE for all folds \n",
    "    maeAvg = scores['test_MAE'].mean()\n",
    "    print_str = \"The average MAE for all cv folds is: \\t\\t\\t {maeAvg:.5}\"\n",
    "    print(print_str.format(maeAvg=maeAvg))\n",
    "\n",
    "    #print mean test_MAPE for all folds\n",
    "    scores['test_MAPE'] = scores['test_MAPE']\n",
    "    mape_avg = scores['test_MAPE'].mean()\n",
    "    print_str = \"The average MAE percentage (MAPE) for all cv folds is: \\t {mape_avg:.5}\"\n",
    "    print(print_str.format(mape_avg=mape_avg))\n",
    "\n",
    "    #print mean MAE for all folds \n",
    "    RMSEavg = scores['test_RMSE'].mean()\n",
    "    print_str = \"The average RMSE for all cv folds is: \\t\\t\\t {RMSEavg:.5}\"\n",
    "    print(print_str.format(RMSEavg=RMSEavg))\n",
    "    print('*********************************************************')\n",
    "\n",
    "    print('Cross Validation Fold Mean Error Scores')\n",
    "    scoresResults = pd.DataFrame()\n",
    "    scoresResults['MAE'] = scores['test_MAE']\n",
    "    scoresResults['MAPE'] = scores['test_MAPE']\n",
    "    scoresResults['RMSE'] = scores['test_RMSE']\n",
    "    return scoresResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modeling and Evaluation 2\n",
    "## Data Sampling Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the classification task's response variable is binary and not balanced - although, as mentioned above, the imbalance was not anticipated to be cause for concern - we used StratifiedShuffleSplit for classification. This ensured that each of the 10 folds would include an overperforming and non-overperforming school. Best results for this stratified 10-fold cross-validation included an 80/20 train-test split.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide data into test and training splits\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "cv_class = StratifiedShuffleSplit(n_splits=10, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the regression tasks, we employed the ShuffleSplit cross-validation with 10 folds to thoroughly randomize our sampling. We found that a 60/40 train/test split yielded the best results for each of our regression tasks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide data into test and training splits\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "cv_reg = ShuffleSplit(n_splits=10, test_size=0.40, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Modeling and Analysis\n",
    "## Classification Tasks\n",
    "We look at three different classification tasks for this project:\n",
    "\n",
    "* Logistic Regression\n",
    "* K Nearest Neighbors\n",
    "* Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "Logistic Regression is a common form of classification for dichotomous variables.  It performs the predictive analysis by estimating the log odds of an event and assigning a binary 1 or 0 dependant upon those log odds.  For logistic regression to effectively classify these values the data shouldn't contain large outliers and no multicollinearity should be present amongst the predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logisticregression', LogisticRegression(C=0.001, class_weight='none', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=0,\n",
       "          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "#create a pipeline to scale all of the data and perform logistic regression during each grid search step.\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "# Define a range of hyper parameters for grid search\n",
    "parameters = { 'logisticregression__penalty':['l2']\n",
    "              ,'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "              ,'logisticregression__class_weight': ['balanced','none']\n",
    "              ,'logisticregression__random_state': [0]\n",
    "              ,'logisticregression__solver': ['lbfgs']\n",
    "              ,'logisticregression__max_iter':[100,500]\n",
    "             }\n",
    "\n",
    "#Perform the grid search using accuracy as a metric during cross validation.\n",
    "grid = GridSearchCV(pipe, parameters, cv=cv_class, scoring='precision')\n",
    "\n",
    "#Use the best features from recursive feature elimination during the grid search\n",
    "grid.fit(X_class, Y_class)\n",
    "\n",
    "#display the best pipeline model identified during the grid search\n",
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy for all cv folds is: \t\t\t 0.85765\n",
      "The average precision for all cv folds is: \t\t\t 0.87108\n",
      "The average recall for all cv folds is: \t\t\t 0.72813\n",
      "*********************************************************\n",
      "Cross Validation Fold Mean Error Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.68750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.68750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.65625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.894118</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.81250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.87500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.75000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.84375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.59375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.62500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.75000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision   Recall\n",
       "0  0.835294   0.846154  0.68750\n",
       "1  0.847059   0.880000  0.68750\n",
       "2  0.835294   0.875000  0.65625\n",
       "3  0.894118   0.896552  0.81250\n",
       "4  0.905882   0.875000  0.87500\n",
       "5  0.882353   0.923077  0.75000\n",
       "6  0.905882   0.900000  0.84375\n",
       "7  0.800000   0.826087  0.59375\n",
       "8  0.800000   0.800000  0.62500\n",
       "9  0.870588   0.888889  0.75000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EvaluateClassifierEstimator(grid.best_estimator_, X_class, Y_class, cv_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors\n",
    "K-Neighbors classifiers measure the distance between points according to a supplied distance metric. Once that distance is calculated, the nearest points - a number of which is identified by the variable *k* - are compared with the current point.  \n",
    "  \n",
    "We utilized a cross-validated GridSearch to obtain the best combination of parameters out of 290 potential models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 290 candidates, totalling 2900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=4)]: Done 353 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=4)]: Done 1097 tasks      | elapsed:   20.3s\n",
      "[Parallel(n_jobs=4)]: Done 2497 tasks      | elapsed:   46.4s\n",
      "[Parallel(n_jobs=4)]: Done 2893 out of 2900 | elapsed:   56.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 2900 out of 2900 | elapsed:   56.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=10, random_state=0, test_size=0.2,\n",
       "            train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'))]),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid={'kneighborsclassifier__n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], 'kneighborsclassifier__weights': ['uniform', 'distance'], 'kneighborsclassifier__metric': ['euclidean', 'chebyshev', 'manhattan', 'minkowski', 'jaccard']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='precision', verbose=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN 10-fold cross-validation \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.spatial.distance import jaccard\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "knc = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_pipe = make_pipeline(StandardScaler(), knc)\n",
    "\n",
    "\n",
    "k_range = list(range(1, 30))\n",
    "metrics = ['euclidean','chebyshev','manhattan','minkowski','jaccard']\n",
    "weights_options = ['uniform','distance']\n",
    "\n",
    "knn_parameters = {'kneighborsclassifier__n_neighbors': k_range,'kneighborsclassifier__weights': weights_options, 'kneighborsclassifier__metric': metrics}\n",
    "\n",
    "#Create a grid search object using the defined parameters\n",
    "\n",
    "kGridSearch = GridSearchCV(knn_pipe,param_grid=knn_parameters,n_jobs=4,verbose=1,cv=cv_class,scoring='precision')\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "kGridSearch.fit(X_class, Y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=28, p=2,\n",
       "           weights='uniform'))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Diplay the top model parameters\n",
    "# kGridSearch.best_params_\n",
    "kGridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy for all cv folds is: \t\t\t 0.82235\n",
      "The average precision for all cv folds is: \t\t\t 0.8736\n",
      "The average recall for all cv folds is: \t\t\t 0.61562\n",
      "*********************************************************\n",
      "Cross Validation Fold Mean Error Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.56250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.53125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.75000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.71875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.62500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.894118</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.78125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.752941</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.43750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.858824</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.75000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision   Recall\n",
       "0  0.788235   0.888889  0.50000\n",
       "1  0.800000   0.857143  0.56250\n",
       "2  0.788235   0.850000  0.53125\n",
       "3  0.882353   0.923077  0.75000\n",
       "4  0.847059   0.851852  0.71875\n",
       "5  0.823529   0.869565  0.62500\n",
       "6  0.894118   0.925926  0.78125\n",
       "7  0.752941   0.823529  0.43750\n",
       "8  0.788235   0.888889  0.50000\n",
       "9  0.858824   0.857143  0.75000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EvaluateClassifierEstimator(kGridSearch.best_estimator_, X_class, Y_class, cv_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "The Random Forest is a relatively new machine learning algorithm, invented in the 1990s. It is an ensemble method extension of the decision tree. As an extension of decision trees, random forests can be used for both classification and regression. We will be focusing exclusively on classification random forest's, but most commentary can be applied to both types of random forests. \n",
    "\n",
    "In the random forest algorithm, you take a random subset of your data's features, grow a shallow decision tree, take note of the predicted class, then repeat that process over and over. The class that is predicted most often by all of the decision trees is the output of the random forest. Given the above description, there are **three primary parameters** available to optimize the algorithm. \n",
    "\n",
    "- **n_features:** This parameter indicates the number of random features to select from the full dataset for each tree in the forest. This can either be a specific number, or a selection method.\n",
    "- **max_depth:** This parameter drives the maximum depth of any of the decision trees grown\n",
    "- **n_estimators:** The number of trees to grow\n",
    "\n",
    "Below is a visual explanation for how the 3 parameters affect a random forest , with the names of the parameters highlighted in red.\n",
    "\n",
    "<center><img src='random_forest.png' width = '75%'></center>\n",
    "\n",
    "There are actually several other parameters available when growing a random forest, they are mostly related to the details of how each individual decision tree is grown. These parameters include the metric used for node splitting (gini impurity or entropy), the minimum number of samples required to split a node, the minimum impurity decrease to split a node, and others.\n",
    "\n",
    "Below we will grow a random forest using the default parameters, and examine the resulting model's quality based on previous discussed metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.93\n",
      "Accuracy: 0.89\n",
      "Recall: 0.79\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, accuracy_score, confusion_matrix, recall_score, f1_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Generate a 60/40 training/test split of data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_class, Y_class, test_size=0.2, random_state=0)\n",
    "# Generate & train instance of RandomForest classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "# Print classification metrics & confusion matrix (normalized & non)\n",
    "print(\"Precision: %0.2f\" % precision_score(y_test, rf.predict(X_test)))\n",
    "print(\"Accuracy: %0.2f\" % accuracy_score(y_test, rf.predict(X_test)))\n",
    "print(\"Recall: %0.2f\" % recall_score(y_test, rf.predict(X_test)))\n",
    "\n",
    "rf_precision = precision_score(y_test, rf.predict(X_test))\n",
    "rf_recall = recall_score(y_test, rf.predict(X_test))\n",
    "rf_accuracy = accuracy_score(y_test, rf.predict(X_test))\n",
    "\n",
    "# Calc and plot confusion matrices\n",
    "cm = confusion_matrix(y_test, rf.predict(X_test))\n",
    "plt.figure(figsize = (11, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_confusion_matrix(cm, ['Non-Outperform', 'Outperform'])\n",
    "plt.title(\"Non-Normalized Confusion Matrix\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_confusion_matrix(cm, ['Non-Outperform', 'Outperform'], normalize=True)\n",
    "plt.title(\"Normalized Confusion Matrix\")\n",
    "plt.ylabel(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In our scenario, the risk of a false positive is great. A false positive would mean indicating a school is likely to outperform when it actually is not. If this model were being used to help direct funds to in-need schools, a false positive would result in a school who really needs help being passed over for additional funding. Conversely, a false negative, where a school is labeled as non-outperform when it actually is doing well doesn't matter too much. The school won't receive additional funding, but they don't need it anyway. Precision is defined as $\\frac{TP}{TP+FP}$ where TP are true positives and FP are false positives. Looking at this formula, you can tell that precision optimizes for reducing false positives. As your FP value goes to 0, the precision score will approach 1 because the numerator and denomitor are equal.\n",
    "\n",
    "Looking across the top row of the confusion matrixes above, it can be seen that for a school who's true label is \"Non-Outperform\", there is a 95% chance of it being correctly labeled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Tasks\n",
    "We look at three different regression tasks for this project:\n",
    "\n",
    "* Ordinary Least Squares (OLS)\n",
    "* Least Absolute Shrinkage and Selection Operation (LASSO)\n",
    "* Huber Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinary Least Squares (OLS)\n",
    "\n",
    "Oridinary Least Squares (OLS) Regression is the standard form of regression well known to students, academics, and industry professionals alike. While it isn't cutting edge, it's a powerful technique used by a huge number of statisticians and data scientists, and always a great place to start a regression analysis. In OLS regression we attempt to estimate the parameters in a linear model by minimizing the sum of squared residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: -14.02 (+/- 16.38)\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.model_selection  import train_test_split\n",
    "from sklearn import linear_model, preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "lr = linear_model.LinearRegression()\n",
    "scores = cross_val_score(lr, X_train, y_train, cv=10, scoring='r2')\n",
    "print(\"R2: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASSO Regression\n",
    "Least Absolute Shrinkage and Selection Operator (LASSO) is a method of linear regression that uses shrinkage to reduce the dimensionality to create a more parsimonious model that best describes the relationship to the predicted variable.  LASSO introduces bias to the model as a penalty to the absolute value of the magnitude of the coefficients.  This bias penalty is aimed at reducing the size of the model to create the simplest model possible.  Thus LASSO is typically far easier to interpret than most other regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=0, test_size=0.4, train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=10000,\n",
       "   normalize=True, positive=False, precompute=True, random_state=0,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=8,\n",
       "       param_grid={'alpha': [0.001, 0.1, 1, 10, 20], 'selection': ['cyclic', 'random'], 'warm_start': [True, False]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(mean_absolute_error, greater_is_better=False),\n",
       "       verbose=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a regression object and perform a grid search to find the best parameters#Create a \n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "reg = Lasso(fit_intercept=True, normalize=True,copy_X=True\n",
    "          , max_iter=10000, precompute=True, tol=0.0001, random_state=0)\n",
    "\n",
    "#Test parameters \n",
    "alpha = [0.001, 0.1, 1, 10, 20]\n",
    "selection = ['cyclic','random']\n",
    "warm_start = [True, False]\n",
    "parameters = {'alpha': alpha, 'selection': selection, 'warm_start': warm_start}\n",
    "\n",
    "#Create a grid search object using the parameters above\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "LassoGridSearch = GridSearchCV(estimator=reg\n",
    "                   , n_jobs=8 # jobs to run in parallel\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv_reg # KFolds = 10\n",
    "                   , scoring=mae_scorer)\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "LassoGridSearch.fit(X_reg, Y_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.001, copy_X=True, fit_intercept=True, max_iter=10000,\n",
       "   normalize=True, positive=False, precompute=True, random_state=0,\n",
       "   selection='cyclic', tol=0.0001, warm_start=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the best estimator parameters#Display  \n",
    "LassoGridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average MAE for all cv folds is: \t\t\t 0.0094198\n",
      "The average MAE percentage (MAPE) for all cv folds is: \t 0.0086863\n",
      "The average RMSE for all cv folds is: \t\t\t 0.016986\n",
      "*********************************************************\n",
      "Cross Validation Fold Mean Error Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010427</td>\n",
       "      <td>0.009131</td>\n",
       "      <td>0.020382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008868</td>\n",
       "      <td>0.008238</td>\n",
       "      <td>0.015705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007894</td>\n",
       "      <td>0.007977</td>\n",
       "      <td>0.012033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010606</td>\n",
       "      <td>0.009174</td>\n",
       "      <td>0.020323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011276</td>\n",
       "      <td>0.010132</td>\n",
       "      <td>0.021148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.011266</td>\n",
       "      <td>0.010064</td>\n",
       "      <td>0.021154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.007652</td>\n",
       "      <td>0.007780</td>\n",
       "      <td>0.011977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.010745</td>\n",
       "      <td>0.009402</td>\n",
       "      <td>0.020462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.008506</td>\n",
       "      <td>0.007902</td>\n",
       "      <td>0.015388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.006958</td>\n",
       "      <td>0.007062</td>\n",
       "      <td>0.011283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MAE      MAPE      RMSE\n",
       "0  0.010427  0.009131  0.020382\n",
       "1  0.008868  0.008238  0.015705\n",
       "2  0.007894  0.007977  0.012033\n",
       "3  0.010606  0.009174  0.020323\n",
       "4  0.011276  0.010132  0.021148\n",
       "5  0.011266  0.010064  0.021154\n",
       "6  0.007652  0.007780  0.011977\n",
       "7  0.010745  0.009402  0.020462\n",
       "8  0.008506  0.007902  0.015388\n",
       "9  0.006958  0.007062  0.011283"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Create a regression estimator with best parameters for cross validation\n",
    "LassoregEstimator = LassoGridSearch.best_estimator_\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics.\n",
    "EvaluateRegressionEstimator(LassoregEstimator, X_reg, Y_reg, cv_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huber Regression\n",
    "The Huber Regression model was selected as a regression model due to its being robust to outliers. We performed a grid search to determine the optimal epsilon - which measures the robustness to outliers - as well as alpha, the regularization parameter. This yielded 560 possible combinations of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 560 candidates, totalling 5600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  71 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=2)]: Done 371 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=2)]: Done 871 tasks      | elapsed:   34.9s\n",
      "[Parallel(n_jobs=2)]: Done 1571 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=2)]: Done 2471 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=2)]: Done 3571 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=2)]: Done 4871 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=2)]: Done 5597 out of 5600 | elapsed:  3.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 5600 out of 5600 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=0, test_size=0.4, train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=HuberRegressor(alpha=0.001, epsilon=1.5, fit_intercept=True, max_iter=100,\n",
       "        tol=1e-05, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=2,\n",
       "       param_grid={'epsilon': array([1.  , 1.05, 1.1 , 1.15, 1.2 , 1.25, 1.3 , 1.35, 1.4 , 1.45, 1.5 ,\n",
       "       1.55, 1.6 , 1.65, 1.7 , 1.75, 1.8 , 1.85, 1.9 , 1.95]), 'alpha': [1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.05, 0.01], 'warm_start': [True, False], 'fit_intercept': [True, False]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(mean_absolute_error, greater_is_better=False),\n",
       "       verbose=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a regression object and perform a grid search to find the best parameters\n",
    "from sklearn.linear_model import HuberRegressor \n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "reg = HuberRegressor(epsilon=1.50,fit_intercept=True, alpha=0.001, max_iter=100)\n",
    "# top_feat = SelectKBest(score_func=chi2, k=75)\n",
    "\n",
    "# pipe = Pipeline([('feature', top_feat), ('huber',reg)])\n",
    "\n",
    "#Test parameters \n",
    "epsilon_range = np.arange(1.0, 2.0, 0.05)\n",
    "alpha_options = [0.0000001, 0.000001, 0.00001, 0.0001, 0.001, 0.05, 0.01]\n",
    "warm_start = [True, False]\n",
    "fit_intercept = [True, False]\n",
    "parameters = {'epsilon': epsilon_range, 'alpha': alpha_options, 'warm_start': warm_start, 'fit_intercept': fit_intercept}\n",
    "\n",
    "#Create a grid search object using the parameters above\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "HuberGridSearch = GridSearchCV(estimator=reg\n",
    "                   , n_jobs=2 # jobs to run in parallel\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv_reg # KFolds = 10\n",
    "                   , scoring=mae_scorer)\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "\n",
    "HuberGridSearch.fit(X_reg, Y_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuberRegressor(alpha=0.05, epsilon=1.9000000000000008, fit_intercept=False,\n",
       "        max_iter=100, tol=1e-05, warm_start=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the best estimator parameters\n",
    "HuberGridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average MAE for all cv folds is: \t\t\t 6.7332\n",
      "The average MAE percentage (MAPE) for all cv folds is: \t 6.379\n",
      "The average RMSE for all cv folds is: \t\t\t 12.086\n",
      "*********************************************************\n",
      "Cross Validation Fold Mean Error Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.207059</td>\n",
       "      <td>6.533801</td>\n",
       "      <td>13.445778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.864356</td>\n",
       "      <td>6.576511</td>\n",
       "      <td>12.737812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.402806</td>\n",
       "      <td>6.600874</td>\n",
       "      <td>10.310756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.355837</td>\n",
       "      <td>6.660856</td>\n",
       "      <td>13.292888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.404944</td>\n",
       "      <td>6.644391</td>\n",
       "      <td>14.352779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.085067</td>\n",
       "      <td>5.386153</td>\n",
       "      <td>11.906259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.014118</td>\n",
       "      <td>6.297595</td>\n",
       "      <td>9.230502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.622230</td>\n",
       "      <td>6.868554</td>\n",
       "      <td>14.106941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.416503</td>\n",
       "      <td>6.037579</td>\n",
       "      <td>11.745375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.959206</td>\n",
       "      <td>6.183579</td>\n",
       "      <td>9.735045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MAE      MAPE       RMSE\n",
       "0  7.207059  6.533801  13.445778\n",
       "1  6.864356  6.576511  12.737812\n",
       "2  6.402806  6.600874  10.310756\n",
       "3  7.355837  6.660856  13.292888\n",
       "4  7.404944  6.644391  14.352779\n",
       "5  6.085067  5.386153  11.906259\n",
       "6  6.014118  6.297595   9.230502\n",
       "7  7.622230  6.868554  14.106941\n",
       "8  6.416503  6.037579  11.745375\n",
       "9  5.959206  6.183579   9.735045"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a regression estimator with best parameters for cross validation\n",
    "HuberregEstimator = HuberGridSearch.best_estimator_\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics.\n",
    "EvaluateRegressionEstimator(HuberregEstimator, X_reg, Y_reg, cv_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Data and Evaluation 4\n",
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Data and Evaluation 5\n",
    "## Advantages and Disadvantages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Data and Evaluation 6\n",
    "## Most Important Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huber Regression\n",
    "\n",
    "We examined the coefficients of the Huber Regression model to determine which attributes were the most important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "huber_imps = pd.DataFrame({\"feature\":X_reg.columns})\n",
    "huber_imps['fscore'] = np.transpose(HuberGridSearch.best_estimator_.coef_.ravel())\n",
    "huber_imps['fscore'] = huber_imps['fscore'] / huber_imps['fscore'].max()\n",
    "huber_imps.sort_values('fscore', ascending = False, inplace = True)\n",
    "huber_imps = huber_imps[0:10]\n",
    "huber_imps.sort_values('fscore', ascending = True, inplace = True)\n",
    "huber_imps.plot(kind='barh', x='feature', y='fscore', legend=False, figsize=(8, 5))\n",
    "plt.title('Huber Regression Feature Importance', fontsize = 16)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.xticks([], [])\n",
    "plt.yticks(fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When examining the ten most important features of the Huber Regression model, we can see from the top four features that graduation rate is influenced largely simply by the number of students at the school compared to the district (lea) and state level. This follows logically, as a school's relative student population size will be a contributing factor to the percentage of that population which graduates. Five of the six remaining features in the top 10 are derived from end of course scores or ACT score-related attributes, as positive results in these academic areas should be reflected by a stable or increasing graduation rate. Lastly, the fifth-most important feature is *Number_Industry_Recognized_Crede*. This is the industry-recognized credentials earned by students, which is also an identifier of academic success and therefore logically translates to graduation rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors\n",
    "\n",
    "Feature importance cannot be as easily ascertained for K-Neighbors classifiers. These classifiers compute distance and look to nearby points to determine class label. Our research indicated that utilizing alternative methods, such as simulated annealing, might be able to yield useful insight in this regard, but with the computational expense being greater than the benefit of the obtained information. See the following R-bloggers article for a lengthier explanation and a demonstration of this in R: https://www.r-bloggers.com/simulated-annealing-feature-selection/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models evaluated in this project would likely prove useful to policy-makers, non-profits, and businesses seeking to target low-performing schools for aid and services.  The  data used by the model is publicly available, albeit with necessary cleanup and precisely classifies successful SAT schools and predicts graduation rates.  It is likely that these interested parties would also be interested in the prevalence and the specificity.  Prevalence indicates how frequently school's overperforming actually occurs.  Specificity is how frequently the model accurately predicts an underperforming school.  Prevalence could be broke up by school district to see an overall success rate for the distict while specificity can be used to accurately show schools in need of serious help.\n",
    "   \n",
    "This dataset could benefit from additional data that could provide tend analysis and additional context to individual schools and school districts.  The data could be merged with previous years data to allow for trend analysis via a time series.  THis could drive predictions about whether a school can sustain the level of academic success expected or aid in detecting schools at risk.  The current dataset focuses entirely on intneral school performance indicators but gives little context about external factors that may affect school performance.  Data on levels of poverty, crime, and economic indicators for the surrounding community of each school or school district could assist policy makers with targeting aid programs intended to help low-income students or where additional security funding is necessary due to high crime.\n",
    "   \n",
    "The model should be updated on an annual basis along with the new data that is generated for the school report cards.  This would allows for new data to be gathered by the state and analyzed and schools to implement changes over the course of an academic year.  Additionally, since the data is only reported on a yearly basis, any model updates generated in the interim would use the same data and likely show similar results to the prior analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Exceptional Work\n",
    "\n",
    "## Random Forest Grid Search\n",
    "\n",
    "In the earlier random forest model, we used the default parameters provided by `scikit-learn`, but those are not necessarily optimal. The defaults for the main parameters are as follows: n_estimators=10, criterion=gini, max_features=auto, max_depth=none. Using the default parameters for a powerful algorithm like random forest is the equivalent of buying a 65 inch 4K HDTV, then playing a VHS tape on it.\n",
    "\n",
    "While it's good we have \"knobs\" to turn on the algorithm, it can be daunting to come up with the optimal set of parameters. Where to start? One option is grid search. In grid search, you take the cartesian product for a set of possible parameter values, and re-run your model for each set of parameters. One of those sets of parameters will have best results, and that is your result. The downside of this approach is that the number of iterations can grow very quickly as you increase the number of parameters & options in your grid, increasing the computational overhead of the model building. Secondly, this method does not guarantee arriving at a global maximum. With those caveats in mind, let's see if/by how much we can increase our model quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With grid search\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 25, 50, 100, 150],\n",
    "    'max_depth':    [int(i) for i in range(2,11)],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'criterion':    ['gini', 'entropy'],\n",
    "    'min_samples_leaf': [2, 4, 6, 8, 10]\n",
    "}\n",
    "\n",
    "# Generate & fit RandomForest with grid search per the above\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "rfgc = RandomForestClassifier(random_state=42)\n",
    "grid_rf = GridSearchCV(rfgc, param_grid, cv=10, scoring=\"precision\")\n",
    "# Careful with the below line of code, it can take a long time to run.\n",
    "#\n",
    "#grid_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-cca43210f3e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\\n Parameters from best model:\\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_rf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nPrecision: %0.2f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_rf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy: %0.2f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_rf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Recall: %0.2f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_rf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n Parameters from best model:\\n\", grid_rf.best_params_)\n",
    "print(\"\\nPrecision: %0.2f\" % precision_score(y_test, grid_rf.predict(X_test)))\n",
    "print(\"Accuracy: %0.2f\" % accuracy_score(y_test, grid_rf.predict(X_test)))\n",
    "print(\"Recall: %0.2f\" % recall_score(y_test, grid_rf.predict(X_test)))\n",
    "\n",
    "crit = 'gini'\n",
    "max_depth = 7\n",
    "max_eatures = 'auto'\n",
    "min_samples_leaf = 4\n",
    "n_estimators = 100\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, grid_rf.predict(X_test))\n",
    "plt.figure(figsize = (11, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_confusion_matrix(cm, ['Non-Outperform', 'Outperform'])\n",
    "plt.title(\"Non-Normalized Confusion Matrix\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_confusion_matrix(cm, ['Non-Outperform', 'Outperform'], normalize=True)\n",
    "plt.title(\"Normalized Confusion Matrix\")\n",
    "plt.ylabel(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Pipeline\n",
    "\n",
    "Although the StandardScaler was used above to normalize the data, that operates under the assumption that the data in our set is well-suited to a standard normal distribution. We therefore combined a **for** loop with a Pipeline to cycle through the data utilizing different scalers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 290 candidates, totalling 2900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=4)]: Done 353 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=4)]: Done 1093 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=4)]: Done 2493 tasks      | elapsed:   51.7s\n",
      "[Parallel(n_jobs=4)]: Done 2893 out of 2900 | elapsed:  1.2min remaining:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 2900 out of 2900 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=10, random_state=0, test_size=0.2,\n",
       "            train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('robustscaler', RobustScaler(copy=True, quantile_range=(25, 75), with_centering=True,\n",
       "       with_scaling=True)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'))]),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid={'kneighborsclassifier__n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], 'kneighborsclassifier__weights': ['uniform', 'distance'], 'kneighborsclassifier__metric': ['euclidean', 'chebyshev', 'manhattan', 'minkowski', 'jaccard']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='precision', verbose=1)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing.data import QuantileTransformer\n",
    "#KNN 10-fold cross-validation \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.spatial.distance import jaccard\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class_cv = StratifiedShuffleSplit(n_splits=10, test_size=0.20, random_state=0)\n",
    "\n",
    "knc = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "scales = {RobustScaler(quantile_range=(25, 75)),\n",
    "         StandardScaler(),\n",
    "         MinMaxScaler(),\n",
    "         MaxAbsScaler(),\n",
    "         QuantileTransformer(output_distribution='uniform'),\n",
    "         QuantileTransformer(output_distribution='normal'),\n",
    "         Normalizer()}\n",
    "\n",
    "k_range = list(range(1, 30))\n",
    "metrics = ['euclidean','chebyshev','manhattan','minkowski','jaccard']\n",
    "weights_options = ['uniform','distance']\n",
    "\n",
    "knn_parameters = {'kneighborsclassifier__n_neighbors': k_range,'kneighborsclassifier__weights': weights_options, 'kneighborsclassifier__metric': metrics}\n",
    "\n",
    "#Create a grid search object using the defined parameters\n",
    "for i in scales:\n",
    "    scaled_knn_pipe = make_pipeline(i, knc)\n",
    "    kGridSearch = GridSearchCV(scaled_knn_pipe,param_grid=knn_parameters,n_jobs=4,verbose=1,cv=class_cv,scoring='precision')\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "kGridSearch.fit(X_class, Y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('robustscaler', RobustScaler(copy=True, quantile_range=(25, 75), with_centering=True,\n",
       "       with_scaling=True)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=2, p=2,\n",
       "           weights='uniform'))])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kGridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy for all cv folds is: \t\t\t 0.75176\n",
      "The average precision for all cv folds is: \t\t\t 0.83711\n",
      "The average recall for all cv folds is: \t\t\t 0.425\n",
      "*********************************************************\n",
      "Cross Validation Fold Mean Error Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.34375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.752941</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.46875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.752941</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.46875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.37500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.811765</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.752941</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.40625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.53125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.28125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.717647</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.37500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision   Recall\n",
       "0  0.741176   0.916667  0.34375\n",
       "1  0.752941   0.789474  0.46875\n",
       "2  0.752941   0.789474  0.46875\n",
       "3  0.741176   0.857143  0.37500\n",
       "4  0.811765   1.000000  0.50000\n",
       "5  0.752941   0.866667  0.40625\n",
       "6  0.776471   0.809524  0.53125\n",
       "7  0.694118   0.750000  0.28125\n",
       "8  0.717647   0.750000  0.37500\n",
       "9  0.776471   0.842105  0.50000"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EvaluateClassifierEstimator(kGridSearch.best_estimator_, X_class, Y_class, cv_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GridSearch determined that the best scaler to use with K-Nearest Neighbors and our data set was a normally distributed quantile transformed scaler. Although precision and accuracy both decreased slightly compared to the standard scaled model above, the recall increased by over 10%. This is indicative of a more balanced model overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
