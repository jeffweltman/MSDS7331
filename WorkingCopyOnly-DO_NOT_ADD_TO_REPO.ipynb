{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2 - Classification and Regression\n",
    "\n",
    "Team Members:\n",
    "* Jeff Weltman\n",
    "* Jordan Kassof\n",
    "* Kevin Dickens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparation \n",
    "## Preparing Target Variables\n",
    "\n",
    "In our classification task, we will be predicting a binary variable that indicates whether or not a highschool's average SAT score is considered \"outperforming.\" This indicator variable is derived based on a threshold applied to the numeric average score. If a school's average SAT score is above 1080, for the purposes of this analysis, it is considered outperforming. While these classes aren't perfectly even, that is expected. It would be surprising to see an equal amount of outperforming and non-outperforming schools. The 262-159 class split isn't large enough for us to worry too much about class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Initial dataset\n",
    "hs_2017 = pd.read_csv(\"hs_2017.csv\")\n",
    "\n",
    "# Preparing the Classification variables\n",
    "Y_class = hs_2017['sat_high_level']\n",
    "X_class = hs_2017.drop(columns=['nc_district', 'sat_high_level', 'sat_avg_score_num'])\n",
    "\n",
    "# Preparing the Regression variables\n",
    "Y_reg = hs_2017['GraduationRate_5yr_All']\n",
    "X_reg = hs_2017.drop(columns=['sat_high_level','sat_avg_score_num','lea_sat_avg_score_num'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Variable\n",
    "\n",
    "In our classification task, we will be predicting a binary integer variable that represents a one-hot encoding of whether or not a highschool's average SAT score \"outperforms\" expectations.  This indicator variable is derived based on a threshold applied to the numeric average score. If a school's average SAT score is above 1080, for the purposes of this analysis, it is considered outperforming. While these classes aren't perfectly even, that is expected. It would be surprising to see an equal amount of outperforming and non-outperforming schools. The 262-159 class split isn't large enough for us to worry too much about class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    262\n",
       "1.0    159\n",
       "Name: sat_high_level, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Classification Variable Balance\n",
    "hs_2017.sat_high_level.value_counts().plot(kind='bar')\n",
    "plt.title(\"Non-Outperform and Outperform Counts\")\n",
    "plt.ylabel(\"Number of Schools\")\n",
    "plt.show()\n",
    "hs_2017.sat_high_level.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Variable\n",
    "\n",
    "In our regression task, we will be predicting the 5-year graduation rate for high schools in the public school system of North Carolina.  This variable represents the percentage of students graduating after five years and is stored as a floating point value.  This data was collected by the north carolina education department for the purpose of tracking school performance.  The distribution of the data follows a normal gaussian distribution although some 0 values are present which create a long tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    100.0\n",
       "1     86.9\n",
       "2     85.7\n",
       "3     74.8\n",
       "4     83.6\n",
       "Name: GraduationRate_5yr_All, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking  Regression Variable Distribution\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cut the window in 2 parts\n",
    "f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\": (.15, .85)})\n",
    " \n",
    "# Add a graph in each part\n",
    "\n",
    "box = sns.boxplot(hs_2017[\"GraduationRate_5yr_All\"], ax=ax_box)\n",
    "dist = sns.distplot(hs_2017[\"GraduationRate_5yr_All\"], ax=ax_hist)\n",
    "\n",
    "box.set_title(\"Distribution of 5 Year Graduation Rates\\n\")\n",
    "\n",
    "# Remove x axis name for the boxplot\n",
    "ax_box.set(xlabel='')\n",
    "\n",
    "plt.show()\n",
    "hs_2017.GraduationRate_5yr_All.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling\n",
    "\n",
    "In an attempt to correct distibution issues, we've scaled the data for both classification and regression tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the data to a more normally distributed data\n",
    "scaler_class = StandardScaler()\n",
    "scaler_class.fit(X_class)\n",
    "\n",
    "scaler_reg = StandardScaler()\n",
    "scaler_reg.fit(X_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Preparation\n",
    "## Final Dataset\n",
    "\n",
    "**TEXT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modeling and Evaluation 1\n",
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "For classification, we opted to use precision as our scoring metric. As we sought to most accurately predict whether a school would overperform on average SAT score, we concluded that minimizing false positives would be of greatest value. The cost of mis-classifying a school as not overperforming when they were, in fact, overperforming was deemed lower than the alternative. \n",
    "\n",
    "Below we define a custom Classification Evaluation function, [created by Dr. Jake Drew](https://github.com/jakemdrew/EducationDataNC/blob/master/2017/Models/2017ComparingSegregatedHighSchoolCampuses.ipynb), to efficiently determine a given model's accuracy, precision, and recall.  \n",
    "We will utilize this function to assess model performance in classifying whether a school is or is not overperforming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def EvaluateClassifierEstimator(classifierEstimator, X, y, cv):\n",
    "   \n",
    "    #Perform cross validation \n",
    "    scores = cross_validate(classifierEstimator, X, y, scoring=['accuracy','precision','recall']\n",
    "                            , cv=cv, return_train_score=True)\n",
    "\n",
    "    Accavg = scores['test_accuracy'].mean()\n",
    "    Preavg = scores['test_precision'].mean()\n",
    "    Recavg = scores['test_recall'].mean()\n",
    "\n",
    "    print_str = \"The average accuracy for all cv folds is: \\t\\t\\t {Accavg:.5}\"\n",
    "    print_str2 = \"The average precision for all cv folds is: \\t\\t\\t {Preavg:.5}\"\n",
    "    print_str3 = \"The average recall for all cv folds is: \\t\\t\\t {Recavg:.5}\"\n",
    "\n",
    "    print(print_str.format(Accavg=Accavg))\n",
    "    print(print_str2.format(Preavg=Preavg))\n",
    "    print(print_str3.format(Recavg=Recavg))\n",
    "    print('*********************************************************')\n",
    "\n",
    "    print('Cross Validation Fold Mean Error Scores')\n",
    "    scoresResults = pd.DataFrame()\n",
    "    scoresResults['Accuracy'] = scores['test_accuracy']\n",
    "    scoresResults['Precision'] = scores['test_precision']\n",
    "    scoresResults['Recall'] = scores['test_recall']\n",
    "\n",
    "    return scoresResults\n",
    "\n",
    "def EvaluateClassifierEstimator2(classifierEstimator, X, y, cv):\n",
    "    \n",
    "    #Perform cross validation \n",
    "    from sklearn.model_selection import cross_val_predict\n",
    "    predictions = cross_val_predict(classifierEstimator, X_Class, Y_Class, cv=cv)\n",
    "    \n",
    "    #model evaluation \n",
    "    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "    \n",
    "    #pass true test set values and predictions to classification_report\n",
    "    classReport = classification_report(Y,predictions)\n",
    "    confMat = confusion_matrix(Y,predictions)\n",
    "    acc = accuracy_score(Y,predictions)\n",
    "    \n",
    "    print(classReport)\n",
    "    print(confMat)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a function to plot out the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression\n",
    "*Root Mean Squared Error* (RMSE) was utilized as our primary regression models' scoring criterion. This represented the degree to which our predicted model deviated from the actual data. It is widely used in regression task as a measurement of variance between the predicted and actual data and was therefore deemed the most appropriate metric for our regression tasks. RMSE is considered appropriate to represent model performance when the error distribution is normally distributed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer, mean_squared_error\n",
    "\n",
    "# Define function for Root mean squared error\n",
    "#https://stackoverflow.com/questions/17197492/root-mean-square-error-in-python\n",
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "#define Function for Mean Absolute Percentage Error (MAPE)\n",
    "#From: https://github.com/jakemdrew/EducationDataNC/blob/master/Other%20Projects/iPython%20Notebooks/Machine%20Learning/Graduation%20Rates%20February%202018%20-%205%20Years%20Expanded.ipynb\n",
    "#Adapted from: https://stackoverflow.com/questions/42250958/how-to-optimize-mape-code-in-python\n",
    "def mape(y, y_pred): \n",
    "    mask = y != 0\n",
    "    return (np.fabs(y - y_pred)/y)[mask].mean() * 100\n",
    "\n",
    "#Scoring functions\n",
    "mae_scorer = make_scorer(score_func=mean_absolute_error, greater_is_better=False)\n",
    "rmse_scorer = make_scorer(score_func=rmse, greater_is_better=False)\n",
    "mape_scorer = make_scorer(score_func=mape, greater_is_better=False)\n",
    "\n",
    "#Array created to score individual folds\n",
    "errorScoring = {'MAE':  mae_scorer, \n",
    "                'RMSE': rmse_scorer,\n",
    "                'MAPE': mape_scorer\n",
    "               }\n",
    "\n",
    "\n",
    "def EvaluateRegressionEstimator(regEstimator, X, y, cv):\n",
    "    \n",
    "    scores = cross_validate(regEstimator, X, y, scoring=errorScoring, cv=cv, return_train_score=True)\n",
    "\n",
    "    #cross val score sign-flips the outputs of MAE\n",
    "    #From: https://github.com/jakemdrew/EducationDataNC/blob/master/Other%20Projects/iPython%20Notebooks/Machine%20Learning/Graduation%20Rates%20February%202018%20-%205%20Years%20Expanded.ipynb\n",
    "    #Adapted from: https://github.com/scikit-learn/scikit-learn/issues/2439\n",
    "    scores['test_MAE'] = scores['test_MAE'] * -1\n",
    "    scores['test_MAPE'] = scores['test_MAPE'] * -1\n",
    "    scores['test_RMSE'] = scores['test_RMSE'] * -1\n",
    "\n",
    "    #print mean MAE for all folds \n",
    "    maeAvg = scores['test_MAE'].mean()\n",
    "    print_str = \"The average MAE for all cv folds is: \\t\\t\\t {maeAvg:.5}\"\n",
    "    print(print_str.format(maeAvg=maeAvg))\n",
    "\n",
    "    #print mean test_MAPE for all folds\n",
    "    scores['test_MAPE'] = scores['test_MAPE']\n",
    "    mape_avg = scores['test_MAPE'].mean()\n",
    "    print_str = \"The average MAE percentage (MAPE) for all cv folds is: \\t {mape_avg:.5}\"\n",
    "    print(print_str.format(mape_avg=mape_avg))\n",
    "\n",
    "    #print mean MAE for all folds \n",
    "    RMSEavg = scores['test_RMSE'].mean()\n",
    "    print_str = \"The average RMSE for all cv folds is: \\t\\t\\t {RMSEavg:.5}\"\n",
    "    print(print_str.format(RMSEavg=RMSEavg))\n",
    "    print('*********************************************************')\n",
    "\n",
    "    print('Cross Validation Fold Mean Error Scores')\n",
    "    scoresResults = pd.DataFrame()\n",
    "    scoresResults['MAE'] = scores['test_MAE']\n",
    "    scoresResults['MAPE'] = scores['test_MAPE']\n",
    "    scoresResults['RMSE'] = scores['test_RMSE']\n",
    "    return scoresResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modeling and Evaluation 2\n",
    "## Data Sampling Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the classification task's response variable is binary and not balanced - although, as mentioned above, the imbalance was not anticipated to be cause for concern - we used StratifiedShuffleSplit for classification. This ensured that each of the 10 folds would include an overperforming and non-overperforming school. Best results for this stratified 10-fold cross-validation included an 80/20 train-test split.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide data into test and training splits\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "cv_class = StratifiedShuffleSplit(n_splits=10, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the regression tasks, we employed the ShuffleSplit cross-validation with 10 folds to thoroughly randomize our sampling. We found that a 60/40 train/test split yielded the best results for each of our regression tasks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide data into test and training splits\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "cv_reg = StratifiedShuffleSplit(n_splits=10, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Modeling and Analysis\n",
    "## Classification Tasks\n",
    "We look at three different classification tasks for this project:\n",
    "\n",
    "* Logistic Regression\n",
    "* K Nearest Neighbors\n",
    "* Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "Logistic Regression is a common form of classification for dichotomous variables.  It performs the predictive analysis by estimating the log odds of an event and assigning a binary 1 or 0 dependant upon those log odds.  For logistic regression to effectively classify these values the data shouldn't contain large outliers and no multicollinearity should be present amongst the predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logisticregression', LogisticRegression(C=0.001, class_weight='none', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=0,\n",
       "          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "#create a pipeline to scale all of the data and perform logistic regression during each grid search step.\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "# Define a range of hyper parameters for grid search\n",
    "parameters = { 'logisticregression__penalty':['l2']\n",
    "              ,'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "              ,'logisticregression__class_weight': ['balanced','none']\n",
    "              ,'logisticregression__random_state': [0]\n",
    "              ,'logisticregression__solver': ['lbfgs']\n",
    "              ,'logisticregression__max_iter':[100,500]\n",
    "             }\n",
    "\n",
    "#Perform the grid search using accuracy as a metric during cross validation.\n",
    "grid = GridSearchCV(pipe, parameters, cv=cv_class, scoring='precision')\n",
    "\n",
    "#Use the best features from recursive feature elimination during the grid search\n",
    "grid.fit(X_class, Y_class)\n",
    "\n",
    "#display the best pipeline model identified during the grid search\n",
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy for all cv folds is: \t\t\t 0.85765\n",
      "The average precision for all cv folds is: \t\t\t 0.87108\n",
      "The average recall for all cv folds is: \t\t\t 0.72813\n",
      "*********************************************************\n",
      "Cross Validation Fold Mean Error Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.68750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.68750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.65625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.894118</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.81250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.87500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.75000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.84375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.59375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.62500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.75000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision   Recall\n",
       "0  0.835294   0.846154  0.68750\n",
       "1  0.847059   0.880000  0.68750\n",
       "2  0.835294   0.875000  0.65625\n",
       "3  0.894118   0.896552  0.81250\n",
       "4  0.905882   0.875000  0.87500\n",
       "5  0.882353   0.923077  0.75000\n",
       "6  0.905882   0.900000  0.84375\n",
       "7  0.800000   0.826087  0.59375\n",
       "8  0.800000   0.800000  0.62500\n",
       "9  0.870588   0.888889  0.75000"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EvaluateClassifierEstimator(grid.best_estimator_, X_class, Y_class, cv_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors\n",
    "K-Neighbors classifiers measure the distance between points according to a supplied distance metric. Once that distance is calculated, the nearest points - a number of which is identified by the variable *k* - are compared with the current point.  \n",
    "  \n",
    "We utilized a cross-validated GridSearch to obtain the best combination of parameters out of 290 potential models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 290 candidates, totalling 2900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=4)]: Done 353 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=4)]: Done 1095 tasks      | elapsed:   20.1s\n",
      "[Parallel(n_jobs=4)]: Done 2495 tasks      | elapsed:   46.2s\n",
      "[Parallel(n_jobs=4)]: Done 2900 out of 2900 | elapsed:   56.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=10, random_state=0, test_size=0.2,\n",
       "            train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'))]),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid={'kneighborsclassifier__n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], 'kneighborsclassifier__weights': ['uniform', 'distance'], 'kneighborsclassifier__metric': ['euclidean', 'chebyshev', 'manhattan', 'minkowski', 'jaccard']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='precision', verbose=1)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN 10-fold cross-validation \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.spatial.distance import jaccard\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "knc = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_pipe = make_pipeline(StandardScaler(), knc)\n",
    "\n",
    "\n",
    "k_range = list(range(1, 30))\n",
    "metrics = ['euclidean','chebyshev','manhattan','minkowski','jaccard']\n",
    "weights_options = ['uniform','distance']\n",
    "\n",
    "knn_parameters = {'kneighborsclassifier__n_neighbors': k_range,'kneighborsclassifier__weights': weights_options, 'kneighborsclassifier__metric': metrics}\n",
    "\n",
    "#Create a grid search object using the defined parameters\n",
    "\n",
    "kGridSearch = GridSearchCV(knn_pipe,param_grid=knn_parameters,n_jobs=4,verbose=1,cv=cv_class,scoring='precision')\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "kGridSearch.fit(X_class, Y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=28, p=2,\n",
       "           weights='uniform'))])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Diplay the top model parameters\n",
    "# kGridSearch.best_params_\n",
    "kGridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy for all cv folds is: \t\t\t 0.82235\n",
      "The average precision for all cv folds is: \t\t\t 0.8736\n",
      "The average recall for all cv folds is: \t\t\t 0.61562\n",
      "*********************************************************\n",
      "Cross Validation Fold Mean Error Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.56250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.53125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.75000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.71875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.62500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.894118</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.78125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.752941</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.43750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.858824</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.75000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision   Recall\n",
       "0  0.788235   0.888889  0.50000\n",
       "1  0.800000   0.857143  0.56250\n",
       "2  0.788235   0.850000  0.53125\n",
       "3  0.882353   0.923077  0.75000\n",
       "4  0.847059   0.851852  0.71875\n",
       "5  0.823529   0.869565  0.62500\n",
       "6  0.894118   0.925926  0.78125\n",
       "7  0.752941   0.823529  0.43750\n",
       "8  0.788235   0.888889  0.50000\n",
       "9  0.858824   0.857143  0.75000"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EvaluateClassifierEstimator(kGridSearch.best_estimator_, X_class, Y_class, cv_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "The Random Forest is a relatively new machine learning algorithm, invented in the 1990s. It is an ensemble method extension of the decision tree. As an extension of decision trees, random forests can be used for both classification and regression. We will be focusing exclusively on classification random forest's, but most commentary can be applied to both types of random forests. \n",
    "\n",
    "In the random forest algorithm, you take a random subset of your data's features, grow a shallow decision tree, take note of the predicted class, then repeat that process over and over. The class that is predicted most often by all of the decision trees is the output of the random forest. Given the above description, there are **three primary parameters** available to optimize the algorithm. \n",
    "\n",
    "- **n_features:** This parameter indicates the number of random features to select from the full dataset for each tree in the forest. This can either be a specific number, or a selection method.\n",
    "- **max_depth:** This parameter drives the maximum depth of any of the decision trees grown\n",
    "- **n_estimators:** The number of trees to grow\n",
    "\n",
    "Below is a visual explanation for how the 3 parameters affect a random forest , with the names of the parameters highlighted in red.\n",
    "\n",
    "<center><img src='random_forest.png' width = '75%'></center>\n",
    "\n",
    "There are actually several other parameters available when growing a random forest, they are mostly related to the details of how each individual decision tree is grown. These parameters include the metric used for node splitting (gini impurity or entropy), the minimum number of samples required to split a node, the minimum impurity decrease to split a node, and others.\n",
    "\n",
    "Below we will grow a random forest using the default parameters, and examine the resulting model's quality based on previous discussed metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.93\n",
      "Accuracy: 0.89\n",
      "Recall: 0.79\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, accuracy_score, confusion_matrix, recall_score, f1_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Generate a 60/40 training/test split of data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_class, Y_class, test_size=0.2, random_state=0)\n",
    "# Generate & train instance of RandomForest classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "# Print classification metrics & confusion matrix (normalized & non)\n",
    "print(\"Precision: %0.2f\" % precision_score(y_test, rf.predict(X_test)))\n",
    "print(\"Accuracy: %0.2f\" % accuracy_score(y_test, rf.predict(X_test)))\n",
    "print(\"Recall: %0.2f\" % recall_score(y_test, rf.predict(X_test)))\n",
    "\n",
    "rf_precision = precision_score(y_test, rf.predict(X_test))\n",
    "rf_recall = recall_score(y_test, rf.predict(X_test))\n",
    "rf_accuracy = accuracy_score(y_test, rf.predict(X_test))\n",
    "\n",
    "# Calc and plot confusion matrices\n",
    "cm = confusion_matrix(y_test, rf.predict(X_test))\n",
    "plt.figure(figsize = (11, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_confusion_matrix(cm, ['Non-Outperform', 'Outperform'])\n",
    "plt.title(\"Non-Normalized Confusion Matrix\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_confusion_matrix(cm, ['Non-Outperform', 'Outperform'], normalize=True)\n",
    "plt.title(\"Normalized Confusion Matrix\")\n",
    "plt.ylabel(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In our scenario, the risk of a false positive is great. A false positive would mean indicating a school is likely to outperform when it actually is not. If this model were being used to help direct funds to in-need schools, a false positive would result in a school who really needs help being passed over for additional funding. Conversely, a false negative, where a school is labeled as non-outperform when it actually is doing well doesn't matter too much. The school won't receive additional funding, but they don't need it anyway. Precision is defined as $\\frac{TP}{TP+FP}$ where TP are true positives and FP are false positives. Looking at this formula, you can tell that precision optimizes for reducing false positives. As your FP value goes to 0, the precision score will approach 1 because the numerator and denomitor are equal.\n",
    "\n",
    "Looking across the top row of the confusion matrixes above, it can be seen that for a school who's true label is \"Non-Outperform\", there is a 95% chance of it being correctly labeled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Tasks\n",
    "We look at three different regression tasks for this project:\n",
    "\n",
    "* Ordinary Least Squares (OLS)\n",
    "* Least Absolute Shrinkage and Selection Operation (LASSO)\n",
    "* Huber Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinary Least Squares (OLS)\n",
    "\n",
    "Oridinary Least Squares (OLS) Regression is the standard form of regression well known to students, academics, and industry professionals alike. While it isn't cutting edge, it's a powerful technique used by a huge number of statisticians and data scientists, and always a great place to start a regression analysis. In OLS regression we attempt to estimate the parameters in a linear model by minimizing the sum of squared residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: -14.02 (+/- 16.38)\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.model_selection  import train_test_split\n",
    "from sklearn import linear_model, preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "lr = linear_model.LinearRegression()\n",
    "scores = cross_val_score(lr, X_train, y_train, cv=10, scoring='r2')\n",
    "print(\"R2: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASSO Regression\n",
    "Least Absolute Shrinkage and Selection Operator (LASSO) is a method of linear regression that uses shrinkage to reduce the dimensionality to create a more parsimonious model that best describes the relationship to the predicted variable.  LASSO introduces bias to the model as a penalty to the absolute value of the magnitude of the coefficients.  This bias penalty is aimed at reducing the size of the model to create the simplest model possible.  Thus LASSO is typically far easier to interpret than most other regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-4da4b4e67c54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m#Perform hyperparameter search to find the best combination of parameters for our data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mregGridSearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_reg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\programfiles\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programfiles\\python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1202\u001b[0m         \"\"\"\n\u001b[0;32m   1203\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1204\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1205\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programfiles\\python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_iter_indices\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1544\u001b[0m         \u001b[0mclass_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1545\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1546\u001b[1;33m             raise ValueError(\"The least populated class in y has only 1\"\n\u001b[0m\u001b[0;32m   1547\u001b[0m                              \u001b[1;34m\" member, which is too few. The minimum\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1548\u001b[0m                              \u001b[1;34m\" number of groups for any class cannot\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "#Create a regression object and perform a grid search to find the best parameters#Create a \n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "reg = Lasso(fit_intercept=True, normalize=True,copy_X=True\n",
    "          , max_iter=10000, precompute=True, tol=0.0001, random_state=0)\n",
    "\n",
    "#Test parameters \n",
    "alpha = [0.001, 0.1, 1, 10, 20]\n",
    "selection = ['cyclic','random']\n",
    "warm_start = [True, False]\n",
    "parameters = {'alpha': alpha, 'selection': selection, 'warm_start': warm_start}\n",
    "\n",
    "#Create a grid search object using the parameters above\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "regGridSearch = GridSearchCV(estimator=reg\n",
    "                   , n_jobs=8 # jobs to run in parallel\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv_reg # KFolds = 10\n",
    "                   , scoring=rmse_scorer)\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "regGridSearch.fit(X_reg, Y_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huber Regression\n",
    "The Huber Regression model was selected as a regression model due to its being robust to outliers. We performed a grid search to determine the optimal epsilon - which measures the robustness to outliers - as well as alpha, the regularization parameter. This yielded 560 possible combinations of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 560 candidates, totalling 5600 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-55b93234f609>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m#Perform hyperparameter search to find the best combination of parameters for our data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mregGridSearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_reg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\programfiles\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programfiles\\python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1202\u001b[0m         \"\"\"\n\u001b[0;32m   1203\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1204\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1205\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programfiles\\python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_iter_indices\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1544\u001b[0m         \u001b[0mclass_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1545\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1546\u001b[1;33m             raise ValueError(\"The least populated class in y has only 1\"\n\u001b[0m\u001b[0;32m   1547\u001b[0m                              \u001b[1;34m\" member, which is too few. The minimum\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1548\u001b[0m                              \u001b[1;34m\" number of groups for any class cannot\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "#Create a regression object and perform a grid search to find the best parameters\n",
    "from sklearn.linear_model import HuberRegressor \n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "reg = HuberRegressor(epsilon=1.50,fit_intercept=True, alpha=0.001, max_iter=100)\n",
    "# top_feat = SelectKBest(score_func=chi2, k=75)\n",
    "\n",
    "# pipe = Pipeline([('feature', top_feat), ('huber',reg)])\n",
    "\n",
    "#Test parameters \n",
    "epsilon_range = np.arange(1.0, 2.0, 0.05)\n",
    "alpha_options = [0.0000001, 0.000001, 0.00001, 0.0001, 0.001, 0.05, 0.01]\n",
    "warm_start = [True, False]\n",
    "fit_intercept = [True, False]\n",
    "parameters = {'epsilon': epsilon_range, 'alpha': alpha_options, 'warm_start': warm_start, 'fit_intercept': fit_intercept}\n",
    "\n",
    "#Create a grid search object using the parameters above\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "regGridSearch = GridSearchCV(estimator=reg\n",
    "                   , n_jobs=2 # jobs to run in parallel\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv_reg # KFolds = 10\n",
    "                   , scoring=rmse_scorer)\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "\n",
    "regGridSearch.fit(X_reg, Y_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Data and Evaluation 4\n",
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Data and Evaluation 5\n",
    "## Advantages and Disadvantages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Data and Evaluation 6\n",
    "## Most Important Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huber Regression\n",
    "\n",
    "We examined the coefficients of the Huber Regression model to determine which attributes were the most important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-940b034a5318>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mhuber_imps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"feature\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mX_reg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mhuber_imps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fscore'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregGridSearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mhuber_imps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fscore'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhuber_imps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fscore'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mhuber_imps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fscore'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mhuber_imps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fscore'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "huber_imps = pd.DataFrame({\"feature\":X_reg.columns})\n",
    "huber_imps['fscore'] = np.transpose(regGridSearch.best_estimator_.coef_.ravel())\n",
    "huber_imps['fscore'] = huber_imps['fscore'] / huber_imps['fscore'].max()\n",
    "huber_imps.sort_values('fscore', ascending = False, inplace = True)\n",
    "huber_imps = huber_imps[0:10]\n",
    "huber_imps.sort_values('fscore', ascending = True, inplace = True)\n",
    "huber_imps.plot(kind='barh', x='feature', y='fscore', legend=False, figsize=(8, 5))\n",
    "plt.title('Huber Regression Feature Importance', fontsize = 16)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.xticks([], [])\n",
    "plt.yticks(fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When examining the ten most important features of the Huber Regression model, we can see from the top four features that graduation rate is influenced largely simply by the number of students at the school compared to the district (lea) and state level. This follows logically, as a school's relative student population size will be a contributing factor to the percentage of that population which graduates. Five of the six remaining features in the top 10 are derived from end of course scores or ACT score-related attributes, as positive results in these academic areas should be reflected by a stable or increasing graduation rate. Lastly, the fifth-most important feature is *Number_Industry_Recognized_Crede*. This is the industry-recognized credentials earned by students, which is also an identifier of academic success and therefore logically translates to graduation rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors\n",
    "\n",
    "Feature importance cannot be as easily ascertained for K-Neighbors classifiers. These classifiers compute distance and look to nearby points to determine class label. Our research indicated that utilizing alternative methods, such as simulated annealing, might be able to yield useful insight in this regard, but with the computational expense being greater than the benefit of the obtained information. See the following R-bloggers article for a lengthier explanation and a demonstration of this in R: https://www.r-bloggers.com/simulated-annealing-feature-selection/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEXT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Exceptional Work\n",
    "\n",
    "## Random Forest Grid Search\n",
    "\n",
    "In the earlier random forest model, we used the default parameters provided by `scikit-learn`, but those are not necessarily optimal. The defaults for the main parameters are as follows: n_estimators=10, criterion=gini, max_features=auto, max_depth=none. Using the default parameters for a powerful algorithm like random forest is the equivalent of buying a 65 inch 4K HDTV, then playing a VHS tape on it.\n",
    "\n",
    "While it's good we have \"knobs\" to turn on the algorithm, it can be daunting to come up with the optimal set of parameters. Where to start? One option is grid search. In grid search, you take the cartesian product for a set of possible parameter values, and re-run your model for each set of parameters. One of those sets of parameters will have best results, and that is your result. The downside of this approach is that the number of iterations can grow very quickly as you increase the number of parameters & options in your grid, increasing the computational overhead of the model building. Secondly, this method does not guarantee arriving at a global maximum. With those caveats in mind, let's see if/by how much we can increase our model quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With grid search\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 25, 50, 100, 150],\n",
    "    'max_depth':    [int(i) for i in range(2,11)],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'criterion':    ['gini', 'entropy'],\n",
    "    'min_samples_leaf': [2, 4, 6, 8, 10]\n",
    "}\n",
    "\n",
    "# Generate & fit RandomForest with grid search per the above\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "rfgc = RandomForestClassifier(random_state=42)\n",
    "grid_rf = GridSearchCV(rfgc, param_grid, cv=10, scoring=\"precision\")\n",
    "# Careful with the below line of code, it can take a long time to run.\n",
    "#\n",
    "#grid_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-cca43210f3e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\\n Parameters from best model:\\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_rf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nPrecision: %0.2f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_rf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy: %0.2f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_rf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Recall: %0.2f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_rf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n Parameters from best model:\\n\", grid_rf.best_params_)\n",
    "print(\"\\nPrecision: %0.2f\" % precision_score(y_test, grid_rf.predict(X_test)))\n",
    "print(\"Accuracy: %0.2f\" % accuracy_score(y_test, grid_rf.predict(X_test)))\n",
    "print(\"Recall: %0.2f\" % recall_score(y_test, grid_rf.predict(X_test)))\n",
    "\n",
    "crit = 'gini'\n",
    "max_depth = 7\n",
    "max_eatures = 'auto'\n",
    "min_samples_leaf = 4\n",
    "n_estimators = 100\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, grid_rf.predict(X_test))\n",
    "plt.figure(figsize = (11, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_confusion_matrix(cm, ['Non-Outperform', 'Outperform'])\n",
    "plt.title(\"Non-Normalized Confusion Matrix\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_confusion_matrix(cm, ['Non-Outperform', 'Outperform'], normalize=True)\n",
    "plt.title(\"Normalized Confusion Matrix\")\n",
    "plt.ylabel(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Pipeline\n",
    "\n",
    "Although the StandardScaler was used above to normalize the data, that operates under the assumption that the data in our set is well-suited to a standard normal distribution. We therefore combined a **for** loop with a Pipeline to cycle through the data utilizing different scalers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 290 candidates, totalling 2900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=4)]: Done 353 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=4)]: Done 1093 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=4)]: Done 2493 tasks      | elapsed:   51.7s\n",
      "[Parallel(n_jobs=4)]: Done 2893 out of 2900 | elapsed:  1.2min remaining:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 2900 out of 2900 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=10, random_state=0, test_size=0.2,\n",
       "            train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('robustscaler', RobustScaler(copy=True, quantile_range=(25, 75), with_centering=True,\n",
       "       with_scaling=True)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'))]),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid={'kneighborsclassifier__n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], 'kneighborsclassifier__weights': ['uniform', 'distance'], 'kneighborsclassifier__metric': ['euclidean', 'chebyshev', 'manhattan', 'minkowski', 'jaccard']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='precision', verbose=1)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing.data import QuantileTransformer\n",
    "#KNN 10-fold cross-validation \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.spatial.distance import jaccard\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class_cv = StratifiedShuffleSplit(n_splits=10, test_size=0.20, random_state=0)\n",
    "\n",
    "knc = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "scales = {RobustScaler(quantile_range=(25, 75)),\n",
    "         StandardScaler(),\n",
    "         MinMaxScaler(),\n",
    "         MaxAbsScaler(),\n",
    "         QuantileTransformer(output_distribution='uniform'),\n",
    "         QuantileTransformer(output_distribution='normal'),\n",
    "         Normalizer()}\n",
    "\n",
    "k_range = list(range(1, 30))\n",
    "metrics = ['euclidean','chebyshev','manhattan','minkowski','jaccard']\n",
    "weights_options = ['uniform','distance']\n",
    "\n",
    "knn_parameters = {'kneighborsclassifier__n_neighbors': k_range,'kneighborsclassifier__weights': weights_options, 'kneighborsclassifier__metric': metrics}\n",
    "\n",
    "#Create a grid search object using the defined parameters\n",
    "for i in scales:\n",
    "    scaled_knn_pipe = make_pipeline(i, knc)\n",
    "    kGridSearch = GridSearchCV(scaled_knn_pipe,param_grid=knn_parameters,n_jobs=4,verbose=1,cv=class_cv,scoring='precision')\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "kGridSearch.fit(X_class, Y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('robustscaler', RobustScaler(copy=True, quantile_range=(25, 75), with_centering=True,\n",
       "       with_scaling=True)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=2, p=2,\n",
       "           weights='uniform'))])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kGridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy for all cv folds is: \t\t\t 0.75176\n",
      "The average precision for all cv folds is: \t\t\t 0.83711\n",
      "The average recall for all cv folds is: \t\t\t 0.425\n",
      "*********************************************************\n",
      "Cross Validation Fold Mean Error Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.34375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.752941</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.46875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.752941</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.46875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.37500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.811765</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.752941</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.40625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.53125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.28125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.717647</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.37500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision   Recall\n",
       "0  0.741176   0.916667  0.34375\n",
       "1  0.752941   0.789474  0.46875\n",
       "2  0.752941   0.789474  0.46875\n",
       "3  0.741176   0.857143  0.37500\n",
       "4  0.811765   1.000000  0.50000\n",
       "5  0.752941   0.866667  0.40625\n",
       "6  0.776471   0.809524  0.53125\n",
       "7  0.694118   0.750000  0.28125\n",
       "8  0.717647   0.750000  0.37500\n",
       "9  0.776471   0.842105  0.50000"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EvaluateClassifierEstimator(kGridSearch.best_estimator_, X_class, Y_class, cv_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GridSearch determined that the best scaler to use with K-Nearest Neighbors and our data set was a normally distributed quantile transformed scaler. Although precision and accuracy both decreased slightly compared to the standard scaled model above, the recall increased by over 10%. This is indicative of a more balanced model overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
